dppo_cat_mountainCar.py 在gym的mountainCar-V0上的测试
dppo_cat_realGame.py 在我们的环境上的代码，较之上面的代码主要的改动为1）在choose_action方法加了action mask；2）网络的unit不一样。
environment_all.py 这个是我们的游戏与真实的游戏之间的转化的脚本




以下是agent的需求和设计思路
需求： 一个agent能够从第一关开始，一关一关的打，直到打过给定的关卡（第n关，n是固定的）。

设计：
1. agent从第一关至第n关 打完一轮为一个episode
2. agent每采取一个动作，并攻打一次当前所处的关卡为一个step
3. 不是在每一个step都可以选到所有动作的，这个需要在choose_action里处理：把actor输出的logits里的非法动作的logit全部变成-9999999， 然后在生成分布。 在actor做梯度的时候不考虑。

Observation（state，共32个）： 
1. 卡牌阵容：list： 9个位置放5个卡牌，[hero_id, hero_id, 0, hero_id,....] 没有卡牌的位置为0
2. 阵容中每个卡牌品质：list： 与上面对应位置有值， [q_id,  q_id, 0, q_id....] 没有卡牌的位置为0
3. 阵容英雄等级： list 与上面对应位置有值， 没有卡牌的位置为0
4. 关卡id
5. 上一次战斗存活的人数
6. 我方与当前关卡对方战力差距
7. 我方当前与我方上一step的战力差距
8. 我方在上一个step对对方造成的伤害
注：暂时不考虑玩家手里的其余卡牌

Reward：
1. 单step的reward： -对方剩余血量/对方总血量   取值范围：[-1, 0]
2. 关卡胜利reward： 1*（1+当前章节已经过的关卡数/当前章节的总关卡数）/上一局的回合数   取值范围：[1, 2]
3. 章节胜利 reward： 10*（1+当前已经完成的章节数/总章节数）。，取值范围：[10, 20]
4. 通关reward： 100000

Action（共5092个）：
1. 英雄上阵： 上阵每一英雄是一个动作
2. 英雄更换位置： 9个位置两两调换是一个动作
3. 英雄升级： 升级一个英雄是一个动作，每次升一级
4. 英雄等级互换： 英雄等级两两互换是一个动作
注：获取资源是系统自动完成，如果这个动作做不了 比如升级，那么就需要过滤掉。


Done ：
1. 打通关
2. 超过每一个episode的最大step数